{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write simple (straightforward) definitions for the following parameters for RandomForestClassifier (https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and indicate how they correlate with the precision and recall for the basic diabetes model we built in class. You will need to rerun the model multiple times to do so.\n",
    "\n",
    "estimators,\n",
    "max_depth,\n",
    "min_samples_split,\n",
    "min_samples_leaf,\n",
    "min_weight_fraction_leaf,\n",
    "max_leaf_nodes,\n",
    "min_impurity_decrease,\n",
    "min_impurity_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimators are the individual models - in this case, the individual decision trees.\n",
    "Reducing the number of estimators tends to reduce the precision and recall of a model.\n",
    "\n",
    "The max_depth puts a cap on the number of levels or \"depth\" each tree is permitted to have.\n",
    "The shallower the depth, the less accurate your precision and recall.  (Introducing a max_depth of 3 drops our model's macro avg recall to 66)\n",
    "\n",
    "min_samples_split requires an internal node to have a certain number of samples in order to split (aka have children branching off of it); its default value is 2.\n",
    "Increasing this number (from the default of 2) seems to follow a parabolic accuracy trend: it increases recall and precision to a point (for this model, around min_samples_split = 11), after which point increased min_samples_split causes diminished recall and precision accuracy.\n",
    "\n",
    "min_samples_leaf is kind of the counterpoint of min_samples_split: it requires a certain number of samples to meet the given criteria in order to form a child leaf off of the parent node (default = 1)\n",
    "Kind of similar to min_samples_split, upping this number seems to increase recall and precision accuracy to a point, after which recall and precision accuracy starts to fall off.\n",
    "\n",
    "min_weight_fraction_leaf: similar to min_samples_leaf, but deals with the weight needed for a leaf node to exist as a fraction of the sum total weights. By default, all samples weighted equally.  You can't go higher than 0.5 in this parameter, which makes sense (if you have two branches and they are weighted equally, each will \"weigh\" 0.5).\n",
    "The higher this number, the more generalized your model and its outputs will be.  Overall, a smaller min_weight_fraction_leaf seems to yield better precision and accuracy, with a few random exceptions - ex. with min_weight_fraction_leaf set to 0.3, precision reaches a macro avg accuracy of 0.78. When you make this number really small (ex. 0.0001, 0.00001), the accuracy scores seem to level off; for this model, macro avg accuracies of about 0.75 (precision) and 0.73 (recall).\n",
    "\n",
    "max_leaf_nodes: caps the number of leaves or terminal nodes on the tree. Prioritizes leaves that do more to reduce impurity.  Reducing this number (I started at 10000) doesn't have much of an effect on accuracy until you reach a certain threshold (for this model, around 100), when recall and precision accuracy begins to diminish.\n",
    "\n",
    "min_impurity_decrease: splits a node if this split induces a decrease of the impurity greater than or equal to this value.  I see it as a form of making the Forest function more efficiently: if splitting a node won't result in additional purity, does it make sense to expend the computing power?  The more refined (smaller) this number, the better accuracy in both precision and recall.\n",
    "\n",
    "min_impurity_split: another method for capping the number of nodes/leaves on a tree.  A node will split if its impurity is above the threshold, otherwise it is a leaf.  However, the documentation says that this parameter has been deprecated since version 0.19, and that min_impurity_decrease should be used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "\n",
    "diabetes_df = pd.read_csv(\"diabetes.csv\")\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = diabetes_df.drop('Outcome', axis=1)\n",
    "y = diabetes_df['Outcome']\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n",
    "\n",
    "#Standardize\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7727272727272727"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=200, min_impurity_decrease=0.0001, random_state=42)\n",
    "#what is an estimator?  models\n",
    "\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       100\n",
      "           1       0.71      0.59      0.65        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.73      0.74       154\n",
      "weighted avg       0.77      0.77      0.77       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = rf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. How does setting bootstrap=False influence the model performance? Note: the default is bootstrap=True. Explain why your results might be so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the documentation, this parameter indicates whether bootstrap samples are used in building the forest's trees.  When set equal to False, the whole dataset is used to create each tree.  As you might expect, using the whole dataset every time a tree is created takes some additional computing power and time, though for this specific model the different isnt drastic (459 ms wall time for default of \"True\" vs. 440 ms wall time for \"False\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 424 ms, sys: 16.2 ms, total: 440 ms\n",
      "Wall time: 459 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7662337662337663"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       100\n",
      "           1       0.70      0.59      0.64        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.73      0.73       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n",
      "CPU times: user 51.2 ms, sys: 3.59 ms, total: 54.8 ms\n",
      "Wall time: 59.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = rf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 426 ms, sys: 8.24 ms, total: 434 ms\n",
      "Wall time: 440 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7662337662337663"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(n_estimators=200, bootstrap='False', random_state=42)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       100\n",
      "           1       0.70      0.59      0.64        54\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.75      0.73      0.73       154\n",
      "weighted avg       0.76      0.77      0.76       154\n",
      "\n",
      "CPU times: user 40 ms, sys: 3.24 ms, total: 43.2 ms\n",
      "Wall time: 50.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = rf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
